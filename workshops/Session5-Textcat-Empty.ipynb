{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: tqdm in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (4.29.1)\n",
      "Requirement already satisfied: lazyme in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (0.0.22)\n",
      "Requirement already satisfied: nltk in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (3.4)\n",
      "Requirement already satisfied: gensim in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (3.7.0)\n",
      "Requirement already satisfied: six in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from nltk) (3.4.0.3)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from gensim) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from gensim) (1.2.0)\n",
      "Requirement already satisfied: boto>=2.32 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (1.9.83)\n",
      "Requirement already satisfied: bz2file in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied: requests in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.83 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.83)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.83->boto3->smart-open>=1.7.0->gensim) (2.7.5)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/kenny/anaconda3/envs/pytorch/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.83->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "/home/kenny/anaconda3/envs/pytorch/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /home/kenny/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install torch tqdm lazyme nltk gensim\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n",
    "\n",
    "Text Categorization (textcat) is a common task in NLP. As long as, we have labelled data and we want to assign a discrete label to every input data point, it's a classification problem. E.g. \n",
    "\n",
    "| Tasks | Possible Labels | \n",
    "|:-|:-|\n",
    "| Sentiment analysis | Positive, Negative, Neutral | \n",
    "| Tweetstorm detection | True, False |\n",
    "| Author profiling | Author1, Author2, ... | \n",
    "| Language Identification | EN, ZH, DE, JA, FR, ...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various datasets for sentiment classification, previously we looked at the movie reviews dataset in `nltk`. There's also this other popular IMDB movie reviews dataset from Stanford. Lets use that.\n",
    "\n",
    "Download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/ and put it in the same directory as where you're running this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munge the data!\n",
    "\n",
    "As always we have to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12500it [00:37, 330.62it/s]\n",
      "12500it [00:38, 326.50it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from lazyme import find_files\n",
    "\n",
    "def tokenize_data(path_to_dir, file_ext):\n",
    "    for filename in tqdm(find_files(path_to_dir, file_ext)):\n",
    "        with open(filename) as fin:\n",
    "            yield word_tokenize(fin.read())\n",
    "        \n",
    "X_train_pos = list(tokenize_data('./aclImdb/train/pos/', '*.txt'))\n",
    "X_train_neg = list(tokenize_data('./aclImdb/train/neg/', '*.txt'))\n",
    "X_test_pos = list(tokenize_data('./aclImdb/test/pos/', '*.txt'))\n",
    "X_test_neg = list(tokenize_data('./aclImdb/test/neg/', '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_pos + X_train_neg\n",
    "X_test = X_test_pos + X_test_neg\n",
    "\n",
    "y_train = ['pos'] * len(X_train_pos) + ['neg'] * len(X_train_neg)\n",
    "y_test = ['pos'] * len(X_test_pos) + ['neg'] * len(X_test_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our IMDB PyTorch Dataset \n",
    "\n",
    "Although we have a binary class problem, we will demonstrate a multi-class solution issue that can be also used on binary classification. \n",
    "\n",
    "\n",
    "First trick is to convert the \"human\" labels to a one-hot encoding.\n",
    "\n",
    "For example, if we have \n",
    "\n",
    "| Text Index | Label |\n",
    "|:-|:-|\n",
    "|0 | pos|\n",
    "|1 |neg|\n",
    "|2 |pos|\n",
    "|3 |neu|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the \n",
    "\n",
    " - first position of the label vector to represent negative  \n",
    " - second to represent positive\n",
    " - third to represent neutral\n",
    "\n",
    "\n",
    "we should represent the labels as such:\n",
    "\n",
    "| Text Index | Label | One-hot |\n",
    "|:-|:-|:-|\n",
    "|0 | 1|[0, 1, 0]|\n",
    "|1 | 0|[1, 0, 0]|\n",
    "|2 | 1|[0, 1, 0]|\n",
    "|3 | 2|[0, 0, 1]|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the one-hot encoding:\n",
    "labels = [1, 0, 1, 2]\n",
    "torch.eye(max(labels)+1)[labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'one_hot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-263aedd91a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# In PyTorch version 1.0.1, simply use this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'one_hot'"
     ]
    }
   ],
   "source": [
    "# In PyTorch version 1.0.1, simply use this:\n",
    "labels = [1, 0, 1, 2]\n",
    "torch.one_hot([1, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.vocab = Dictionary(texts)\n",
    "        # Vectorize labels\n",
    "        label_set = {'neg':0, 'pos':1}\n",
    "        labels = [label_set[l] for l in labels]\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        return {'x':vectorized_sent, \n",
    "                'y':self.labels[index], \n",
    "                'x_len':len(vectorized_sent)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(self.vocab.doc2idx(tokens))\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = IMDBDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([ 11,  12,  49,  24,  35,  38,   6,  15,  69,  31,  93,  76,  97,  30,\n",
      "         84,  62,  68,  25,  79,  53,   5,  87,  30,  23,  18,   2,   6,  16,\n",
      "          8, 103,  47,  93,  90,  67,  52,  56,  98,  32,  92,  11,  12,   4,\n",
      "         77,  49,  57,  37,  98,  70,  91,  49,  23,  18,   2,   6,  19,  81,\n",
      "         98,  88,  44,   5,  93,  48,  86, 101,  34,  82,  74,  96,  94,  63,\n",
      "         89,   1,  66,   5,  93,  64,  60,  93, 102,  83,   5,  28,  72,  56,\n",
      "         60,  93,  80,  13,  51,  29,  94,  86,   6,  22,  13,  78,  93,  40,\n",
      "         47, 100,  24,  85,  73,  99,  98,  33,  39,  93,  79,   5,  13,  46,\n",
      "         71,   7,   7,   7,  31,   7,   7,   7,   6,  12,   6,  10,  36,  54,\n",
      "          9,  14,   9,  13,   3,  45,  98,  75,  61,  60, 104,  89,   6,  17,\n",
      "          9,  20,  98,  11,  12,   6,  13,  41,  92,  55,  26,  60,  58,  27,\n",
      "         95,  92,  11,  12,  49,  42,  43,   6,  21,  24,  65,  92,  50,  49,\n",
      "         59,   0]), 'y': tensor(1), 'x_len': 170}\n"
     ]
    }
   ],
   "source": [
    "print(imdb_data[0]) # First data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch DataLoader\n",
    "\n",
    "The [`torch.utils.data.DataLoader` object](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)  will help us easily create batches from the `torch.utils.data.Dataset` so that we can do mini-batch SGD and fully utilize GPU/CPU computation during gradient optimization.\n",
    "\n",
    "The `DataLoader` requires the following function to be implemented in the `Dataset`:\n",
    "\n",
    " - `__getitem__`: Return the dictionary of inputs \n",
    " - `__len__`: Return the no. of indices that `__getitem__` can fetch\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[11054, 27740,    49, 24878, 33449,     5,    24,  7623,  3236,  6372,\n",
      "           101,    49,  6500,   376,    60, 23114,   311,   206,     4,  6500,\n",
      "            98,  3630,   209,    93,    53,    60,   209,  7005, 40299,   107,\n",
      "         63186, 63187,   108,   311,   206, 54900,   299,   253,    24,   468,\n",
      "             5,   168,  6713,   209,  7855,   468,    60,  4138,  5582,  5957,\n",
      "            47,    61,   529,     6,   124,   204,    98,  1269,  1392,   209,\n",
      "           847,  3353,    92,   206,    34,  1073,    98,   207,   821,   432,\n",
      "            50,   252,    29,  1269,   209, 26302,   376,    60, 63213,     6,\n",
      "           118,    93,  2987,   156,   584,   821,     5,   437,    34,   206,\n",
      "           432,    50,   252,   113,   331,   308,    61,    60,    93,  1200,\n",
      "         10842,    60,    24,   190,    98, 28228,    30,    93,  8639,   308,\n",
      "            42,   196,    24,    36,     6,   605,   213,   322,   182,    59,\n",
      "          1038,   694,    50,  1196,    57,     5,    29,  1530,    93,  5537,\n",
      "          5715,    60,   104,  8513,   252,   437,   322,    34, 13842,    93,\n",
      "           262,  5458, 53549,   219,   388,    93,   373,   193,   310,    50,\n",
      "            49,     6,   639,   105,   184,   299,  4049,    93,  3901,     6,\n",
      "          2139,    50,   253,    24, 59862,   315,    23,    19, 11418,    29,\n",
      "            93, 11891,     2,   193,    24,   529,    60, 63214, 17034,     5,\n",
      "           219,   182,    59,   388,    93,  3236,   376,   193,    24, 10342,\n",
      "            74, 13423,   111,   164,   109,   112,   111,   164,   109,   112,\n",
      "            16,  5506,     9,  8060,   111,   164,   109,   112,   111,   164,\n",
      "           109,   112,   902,  8629,     9,  4276,  3930,  6688, 34805, 23961,\n",
      "           110, 34805, 63210,   110, 10109, 63211,     9, 56232, 44136,   110,\n",
      "            19,  3275, 10306,   110,    23,  9273,   916,  4466,     2, 12025,\n",
      "           110,    23,  8331, 37393,     2, 12025,   110, 10792,  3288,    19,\n",
      "         46244,   110,    19, 62919,    23, 63212,  3288,    19,  3890,     2,\n",
      "          3311,   744,   110, 15705,  8648,     5,    29,  8649,   193,    23,\n",
      "         31670,  1106,     2,     5,    23,  1672,    98, 13899,     2,    29,\n",
      "            23, 13008, 13011,     2]]), 'y': tensor([1]), 'x_len': tensor([284])}\n"
     ]
    }
   ],
   "source": [
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try batch of size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 189 and 454 in dimension 1 at /opt/conda/conda-bld/pytorch-cpu_1544218188686/work/aten/src/TH/generic/THTensorMoreMath.cpp:1333",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0751de8e3cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimdb_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Sort indices of data in batch by lengths.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 189 and 454 in dimension 1 at /opt/conda/conda-bld/pytorch-cpu_1544218188686/work/aten/src/TH/generic/THTensorMoreMath.cpp:1333"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotcha! Everything should be a fixed-size tensor\n",
    "\n",
    "To use the `DataLoader` to generate batches, one thing that we need to keep consistent is the size of the tensors for our inputs and outputs. \n",
    "\n",
    "For the outputs (`y`), it shouldn't be much of a problem since they are already in fixed size one-hot encoding.\n",
    "\n",
    "It's the inputs (`x`), that has variable length and we need to somehow fix it. \n",
    "\n",
    "There are a couple of ways to accomplish the fixed-size inputs:\n",
    "\n",
    " - Set the size of `x` tensors to a certain size and cut-off extra words after that\n",
    " - Set the size of `x` tensors to the max length seen in the train data and pad the other data points with lower length with a special `<pad>` symbol. \n",
    " \n",
    " \n",
    "Lets do both:\n",
    "\n",
    " - Set a max size limit\n",
    " - For sentences that has length > max, we cut the rest of the sentence off\n",
    " - For sentences that has length < max, we pad till we reach the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([-0.5593, -0.1504, -0.1062, -0.3134,  0.9965, -0.4380, -0.7861,  1.1467,\n",
      "         0.1388,  0.6459])\n"
     ]
    }
   ],
   "source": [
    "# Here's a clean way to pad 1-Dimensional tensors in PyTorch\n",
    "a = torch.randn(10)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "tensor([-0.5593, -0.1504, -0.1062, -0.3134,  0.9965, -0.4380, -0.7861,  1.1467,\n",
      "         0.1388,  0.6459,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "max_len = 15\n",
    "pad_left = 0\n",
    "pad_right = max_len - len(a)\n",
    "b = F.pad(a, (pad_left, pad_right), 'constant')\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to rewrite the `IMDBDataset` to account for fixed-length `x` tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        \n",
    "        # Remember the `patch_with_special_tokens` from gensim?\n",
    "        # Now we can put it into good use.\n",
    "        special_tokens = {'<pad>': 0, '<unk>':1}\n",
    "        self.vocab = Dictionary(texts)\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        # Keep track of vocab size.\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Vectorize labels\n",
    "        label_set = {'neg':0, 'pos':1}\n",
    "        labels = [label_set[l] for l in labels]\n",
    "        # Keep track of num of labels.\n",
    "        self.num_labels = max(labels)+1\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "        self.labels_onehot = torch.eye(self.num_labels)[labels].long()\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len-len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent, \n",
    "                'y':self.labels[index], \n",
    "                'x_len':len(vectorized_sent)}\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(self.vocab.doc2idx(tokens, unknown_word_index=1))\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = IMDBDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.vocab.token2id['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([11, 12, 49,  ...,  0,  0,  0]), 'y': tensor(1), 'x_len': 2818}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[331, 373,  49,  ...,   0,   0,   0]]), 'y': tensor([1]), 'x_len': tensor([2818])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-5].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with Feed-Forward Net\n",
    "\n",
    "Now that we have everything about the data in place, we can make use of all the knowledge we've gained thus far:\n",
    "\n",
    " - **Multi-Layered Perceptron**, aka. **Feed-Forward Network** that we've learnt from the previous XOR examples\n",
    "   - *Linear* layers\n",
    "   - *Activation function*, which?\n",
    "   - *Criterion* which?\n",
    "   - *Optimizer*, Adam vs SGD\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim=2\n",
    "max_len=2818\n",
    "class FFNet(nn.Module):\n",
    "    def __init__(self, max_len, num_labels, vocab_size, embedding_size, hidden_dim):\n",
    "        super(FFNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embedding_size, \n",
    "                                       padding_idx=0)\n",
    "        # The no. of inputs to the linear layer is the \n",
    "        # no. of tokens in each input * embedding_size\n",
    "        self.linear1 = nn.Linear(max_len*embedding_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # We want to flatten the inputs so that we get the matrix of shape.\n",
    "        # batch_size x no. of tokens in each input * embedding_size\n",
    "        batch_size, max_len = inputs.shape\n",
    "        embedded = self.embeddings(inputs).view((batch_size, -1)) # Change the size of the embedded matrix.\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        return F.sigmoid(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863227486610413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embedding_size = 100\n",
    "learning_rate = 0.003\n",
    "hidden_size = 100\n",
    "\n",
    "# Initialize the dataset.\n",
    "batch_size = 5\n",
    "imdb_data = imdb_data = IMDBDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Hint: the CBOW model object you've created.\n",
    "model = FFNet(imdb_data.max_len, \n",
    "              imdb_data.num_labels, \n",
    "              imdb_data.vocab_size, \n",
    "              embedding_size=embedding_size, \n",
    "              hidden_dim=hidden_size)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "losses = []\n",
    "num_epochs = 3\n",
    "for _e in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        x = batch['x'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        # Zero gradient.\n",
    "        optimizer.zero_grad()\n",
    "        # Feed forward.\n",
    "        predictions = model(x)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(float(loss))\n",
    "        break\n",
    "    print(sum(epoch_loss)/len(epoch_loss))\n",
    "    break\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4852, 0.4908, 0.4801, 0.4784, 0.4959], grad_fn=<MaxBackward0>),\n",
       " tensor([1, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(predictions, 1)  # Predictions of the last batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actor', 'turned', 'director', 'Bill', 'Paxton', 'follows', 'up', 'his', 'promising', 'debut', ',', 'the', 'Gothic-horror', '``', 'Frailty', \"''\", ',', 'with', 'this', 'family', 'friendly', 'sports', 'drama', 'about', 'the', '1913', 'U.S.', 'Open', 'where', 'a', 'young', 'American', 'caddy', 'rises', 'from', 'his', 'humble', 'background', 'to', 'play', 'against', 'his', 'Bristish', 'idol', 'in', 'what', 'was', 'dubbed', 'as', '``', 'The', 'Greatest', 'Game', 'Ever', 'Played', '.', \"''\", 'I', \"'m\", 'no', 'fan', 'of', 'golf', ',', 'and', 'these', 'scrappy', 'underdog', 'sports', 'flicks', 'are', 'a', 'dime', 'a', 'dozen', '(', 'most', 'recently', 'done', 'to', 'grand', 'effect', 'with', '``', 'Miracle', \"''\", 'and', '``', 'Cinderella', 'Man', \"''\", ')', ',', 'but', 'some', 'how', 'this', 'film', 'was', 'enthralling', 'all', 'the', 'same.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'film', 'starts', 'with', 'some', 'creative', 'opening', 'credits', '(', 'imagine', 'a', 'Disneyfied', 'version', 'of', 'the', 'animated', 'opening', 'credits', 'of', 'HBO', \"'s\", '``', 'Carnivale', \"''\", 'and', '``', 'Rome', \"''\", ')', ',', 'but', 'lumbers', 'along', 'slowly', 'for', 'its', 'first', 'by-the-numbers', 'hour', '.', 'Once', 'the', 'action', 'moves', 'to', 'the', 'U.S.', 'Open', 'things', 'pick', 'up', 'very', 'well', '.', 'Paxton', 'does', 'a', 'nice', 'job', 'and', 'shows', 'a', 'knack', 'for', 'effective', 'directorial', 'flourishes', '(', 'I', 'loved', 'the', 'rain-soaked', 'montage', 'of', 'the', 'action', 'on', 'day', 'two', 'of', 'the', 'open', ')', 'that', 'propel', 'the', 'plot', 'further', 'or', 'add', 'some', 'unexpected', 'psychological', 'depth', 'to', 'the', 'proceedings', '.', 'There', \"'s\", 'some', 'compelling', 'character', 'development', 'when', 'the', 'British', 'Harry', 'Vardon', 'is', 'haunted', 'by', 'images', 'of', 'the', 'aristocrats', 'in', 'black', 'suits', 'and', 'top', 'hats', 'who', 'destroyed', 'his', 'family', 'cottage', 'as', 'a', 'child', 'to', 'make', 'way', 'for', 'a', 'golf', 'course', '.', 'He', 'also', 'does', 'a', 'good', 'job', 'of', 'visually', 'depicting', 'what', 'goes', 'on', 'in', 'the', 'players', \"'\", 'heads', 'under', 'pressure', '.', 'Golf', ',', 'a', 'painfully', 'boring', 'sport', ',', 'is', 'brought', 'vividly', 'alive', 'here', '.', 'Credit', 'should', 'also', 'be', 'given', 'the', 'set', 'designers', 'and', 'costume', 'department', 'for', 'creating', 'an', 'engaging', 'period-piece', 'atmosphere', 'of', 'London', 'and', 'Boston', 'at', 'the', 'beginning', 'of', 'the', 'twentieth', 'century.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'You', 'know', 'how', 'this', 'is', 'going', 'to', 'end', 'not', 'only', 'because', 'it', \"'s\", 'based', 'on', 'a', 'true', 'story', 'but', 'also', 'because', 'films', 'in', 'this', 'genre', 'follow', 'the', 'same', 'template', 'over', 'and', 'over', ',', 'but', 'Paxton', 'puts', 'on', 'a', 'better', 'than', 'average', 'show', 'and', 'perhaps', 'indicates', 'more', 'talent', 'behind', 'the', 'camera', 'than', 'he', 'ever', 'had', 'in', 'front', 'of', 'it', '.', 'Despite', 'the', 'formulaic', 'nature', ',', 'this', 'is', 'a', 'nice', 'and', 'easy', 'film', 'to', 'root', 'for', 'that', 'deserves', 'to', 'find', 'an', 'audience', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1]) # First test review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ab8beda5162c>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ab8beda5162c>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    pad_dim = ???\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def vectorize_test_inputs(inputs):\n",
    "    # Process the input text in the same way as you did with the training data.\n",
    "    vectorized_sent = imdb_data.vectorize(inputs)\n",
    "    pad_dim = ???\n",
    "    padded_sent = ???\n",
    "    return padded_sent.unsqueeze(0)\n",
    "\n",
    "print('Input tensor:', vectorize_test_inputs(X_test[0]))\n",
    "label_set = {'neg':0, 'pos':1}\n",
    "print('Label:', label_set[y_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5093, 0.5479])\n",
      "tensor([0.4903, 0.5097])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Apply the model to the inputs.\n",
    "with torch.no_grad():\n",
    "    predictions = model(vectorize_test_inputs(X_test[0])).unsqueeze(0)\n",
    "    print(predictions)\n",
    "    print(F.softmax(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
