{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports we need.\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Terms</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kopi O</td>\n",
       "      <td>Black Coffee with Sugar</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kopi</td>\n",
       "      <td>Black Coffee with Condensed Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kopi C</td>\n",
       "      <td>Black Coffee with Evaporated Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kopi Kosong</td>\n",
       "      <td>Black Coffee without sugar or milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kopi Gah Dai</td>\n",
       "      <td>Black Coffee with extra condensed milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Local Terms                                 Meaning  \\\n",
       "0        Kopi O                 Black Coffee with Sugar   \n",
       "1          Kopi        Black Coffee with Condensed Milk   \n",
       "2        Kopi C       Black Coffee with Evaporated Milk   \n",
       "3   Kopi Kosong      Black Coffee without sugar or milk   \n",
       "4  Kopi Gah Dai  Black Coffee with extra condensed milk   \n",
       "\n",
       "                                              Source  \n",
       "0  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "1  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "2  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "3  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "4  https://daneshd.com/2010/02/28/a-rough-guide-t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Reads the tab-delimited data using Pandas.\n",
    "kopitiam = pd.read_csv('kopitiam.csv')\n",
    "kopitiam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "singlish_sents = [START] + kopitiam['Local Terms'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "english_sents = [START] + kopitiam['Meaning'].apply(str.lower).apply(word_tokenize) + [END]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Singlish sentence:\t ['<s>', 'kopi', 'o', '</s>']\n",
      "First English sentence:\t\t ['<s>', 'black', 'coffee', 'with', 'sugar', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First Singlish sentence:\\t', singlish_sents[0])\n",
    "print('First English sentence:\\t\\t', english_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KopitiamDataset(Dataset):\n",
    "    def __init__(self, src_sents, trg_sents, max_len=-1):\n",
    "        assert len(src_sents) == len(trg_sents), \"There should be the same no. of sentence for both source and target.\"\n",
    "        self.src_sents = src_sents\n",
    "        self.trg_sents = trg_sents\n",
    "\n",
    "        # Create the vocabulary for both the source and target.\n",
    "        self.src_vocab = Dictionary(src_sents)\n",
    "        self.trg_vocab = Dictionary(trg_sents)\n",
    "        \n",
    "        # Patch the vocabularies and add the <pad> and <unk> symbols.\n",
    "        special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
    "        self.src_vocab.patch_with_special_tokens(special_tokens)\n",
    "        self.trg_vocab.patch_with_special_tokens(special_tokens)\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(src_sents)\n",
    "        \n",
    "        if max_len < 0:\n",
    "            # If it's not set, find the longest text in the data.\n",
    "            max_src_len = max(len(sent) for sent in src_sents)\n",
    "            max_trg_len = max(len(sent) for sent in trg_sents)\n",
    "            self.max_len = max(max_src_len, max_trg_len)\n",
    "        else:\n",
    "            self.max_len = max_len\n",
    "        \n",
    "    def pad_sequence(self, vectorized_sent, max_len):\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, max_len - len(vectorized_sent))\n",
    "        return F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_src = self.vectorize(self.src_vocab, self.src_sents[index])\n",
    "        vectorized_trg = self.vectorize(self.trg_vocab, self.trg_sents[index])\n",
    "        \n",
    "        return {'x':self.pad_sequence(vectorized_src, self.max_len), \n",
    "                'y':self.pad_sequence(vectorized_trg, self.max_len), \n",
    "                'x_len':len(vectorized_src), \n",
    "                'y_len':len(vectorized_trg)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, vocab, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(vocab.doc2idx(tokens))\n",
    "    \n",
    "    def unvectorize(self, vocab, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kopi_data = KopitiamDataset(singlish_sents, english_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[ 2, 68, 67,  9,  8,  6,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 2, 49, 46,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 2, 68, 50,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0]]), 'y': tensor([[  2,  24, 117, 116,   5,  25, 116,  27,  23,  25,   4,   3,   0,   0,\n",
      "           0,   0,   0,   0,   0],\n",
      "        [  2,  56,   5,  55,  54,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0],\n",
      "        [  2,  82,  26,  83,  84,  61, 116,   5,  59,  19,  57,  81,  80,  76,\n",
      "          74,  70,  67,   3,   0]]), 'x_len': tensor([7, 4, 4]), 'y_len': tensor([12,  6, 18])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(dataset=kopi_data, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=True)\n",
    "\n",
    "def sort_batch_by_len(data_dict):\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    return data_batch\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    data_batch = sort_batch_by_len(data_dict)\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, we have tensors with variable lengths.\n",
    "t1 = torch.tensor([2, 13, 5, 8, 3]).float()\n",
    "t2 = torch.tensor([2, 10, 3]).float()\n",
    "t3 = torch.tensor([2, 10, 1, 3]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5 and 3 in dimension 1 at c:\\a\\w\\1\\s\\tmp_conda_3.6_091443\\conda\\conda-bld\\pytorch_1544087948354\\work\\aten\\src\\th\\generic/THTensorMoreMath.cpp:1333",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2899f125d7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# If the dimensions are different, you can't even stack them into a matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5 and 3 in dimension 1 at c:\\a\\w\\1\\s\\tmp_conda_3.6_091443\\conda\\conda-bld\\pytorch_1544087948354\\work\\aten\\src\\th\\generic/THTensorMoreMath.cpp:1333"
     ]
    }
   ],
   "source": [
    "# If the dimensions are different, you can't even stack them into a matrix.\n",
    "torch.stack([t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., 13.,  5.,  8.,  3.],\n",
       "        [ 2., 10.,  3.,  0.,  0.],\n",
       "        [ 2., 10.,  1.,  3.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we have to pad them, e.g. \n",
    "_max_len = max(len(t1), len(t2), len(t3))\n",
    "\n",
    "t1 = F.pad(t1, (0, _max_len-len(t1)), 'constant')\n",
    "t2 = F.pad(t2, (0, _max_len-len(t2)), 'constant')\n",
    "t3 = F.pad(t3, (0, _max_len-len(t3)), 'constant')\n",
    "\n",
    "torch.stack([t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 68, 67,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0],\n",
       "        [ 2, 68,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0],\n",
       "        [ 2, 68,  4,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(dataset=kopi_data, batch_size=batch_size, \n",
    "                        shuffle=False)\n",
    "\n",
    "# Hack to make dataloader give us the first batch.\n",
    "data_batch = next(iter(dataloader)) \n",
    "\n",
    "data_batch['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch['x_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'lengths' array has to be sorted in decreasing order",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0f3409590a06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m packed_tensor = pack_padded_sequence(data_batch['x'],\n\u001b[0;32m      2\u001b[0m                                      \u001b[0mdata_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                      batch_first=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpacked_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Prog_files\\Anaconda\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first)\u001b[0m\n\u001b[0;32m    146\u001b[0m                       category=torch.jit.TracerWarning, stacklevel=2)\n\u001b[0;32m    147\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 'lengths' array has to be sorted in decreasing order"
     ]
    }
   ],
   "source": [
    "packed_tensor = pack_padded_sequence(data_batch['x'],\n",
    "                                     data_batch['x_len'], \n",
    "                                     batch_first=True)\n",
    "packed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([ 2,  2,  2, 68, 49, 68, 67, 46, 50,  9,  3,  3,  8,  6,  3]), batch_sizes=tensor([3, 3, 3, 3, 1, 1, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(dataset=kopi_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def sort_batch_by_len(data_batch):\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    return data_batch\n",
    "\n",
    "\n",
    "# Hack to make dataloader give us the first batch.\n",
    "data_batch = next(iter(dataloader)) \n",
    "\n",
    "# Apply the `pack_padded_sequence` to the batch.\n",
    "data_batch = sort_batch_by_len(data_batch)\n",
    "packed_tensor = pack_padded_sequence(data_batch['x'], data_batch['x_len'], batch_first=True)\n",
    "packed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_padded_x_tensors = tensor(\n",
    "    [[ 2, 13,  6,  3,  0,  0,  0,  0,  0],\n",
    "     [ 2, 68,  3,  0,  0,  0,  0,  0,  0],\n",
    "     [ 2, 68, 67,  5,  3,  0,  0,  0,  0]\n",
    "    ])\n",
    "\n",
    "_tensor_lens = [4, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, to perform any operations within the tensors, \n",
    "# it's easiest to cast them into numpy arrays\n",
    "np.array(_tensor_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the `.argsort()` function in the numpy array\n",
    "# would return an array of the indices sorted by their\n",
    "# values in ascending order.\n",
    "np.array(_tensor_lens).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But for the `pack_padded_sequence`, we want our \n",
    "# tensor lengths to be sorted in a descending order, \n",
    "# so we do a reverse.\n",
    "\n",
    "# Normally you can use the native python `reversed()` \n",
    "# function and the idiom looks as below, but that will\n",
    "# lose the np.array object\n",
    "list(reversed(np.array(_tensor_lens).argsort()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To keep the np.array object, \n",
    "# we can use the [::-1] slice notion to reverse the array.\n",
    "# See https://stackoverflow.com/a/31633656/610569 \n",
    "np.array(_tensor_lens).argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 5]\n",
      "tensor([[ 2, 13,  6,  3,  0,  0,  0,  0,  0],\n",
      "        [ 2, 68,  3,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2, 68, 67,  5,  3,  0,  0,  0,  0]])\n",
      "\n",
      "[5, 4, 3]\n",
      "tensor([[ 2, 68, 67,  5,  3,  0,  0,  0,  0],\n",
      "        [ 2, 13,  6,  3,  0,  0,  0,  0,  0],\n",
      "        [ 2, 68,  3,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Sort the indices by descending order.\n",
    "sorted_indices = np.array(_tensor_lens).argsort()[::-1].tolist()\n",
    "# Use the slice notation on the tensor to reorder the tensor.\n",
    "print(_tensor_lens)\n",
    "print(_padded_x_tensors)\n",
    "print()\n",
    "print(sorted(_tensor_lens, reverse=True))\n",
    "print(_padded_x_tensors[sorted_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  2,  2],\n",
       "         [68, 49, 68],\n",
       "         [67, 46, 50],\n",
       "         [ 9,  3,  3],\n",
       "         [ 8,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 3,  0,  0]]), tensor([7, 4, 4]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you didn't specify the batch_first argument, you see that our tensors got transposed.\n",
    "pad_packed_sequence(packed_tensor, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 68, 67,  9,  8,  6,  3],\n",
       "        [ 2, 49, 46,  3,  0,  0,  0],\n",
       "        [ 2, 68, 50,  3,  0,  0,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get back the original tensor before packing, we set batch_first=True.\n",
    "unpacked_tensor, unpacked_tensor_len = pad_packed_sequence(packed_tensor, batch_first=True)\n",
    "unpacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked_tensor_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size,\n",
    "                                      padding_idx=0)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    " \n",
    "    def forward(self, inputs, inputs_lengths):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Create PackedSequence\n",
    "        lengths = inputs_lengths.detach().cpu().numpy()\n",
    "        embedded_packed = pack_padded_sequence(embedded, lengths, \n",
    "                                               batch_first=True)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded_packed)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size,\n",
    "                                     padding_idx=0)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Initialize the \"classifier\" linear layer.\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input.size(0)\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = embedded.permute(1, 0, 2) # S=1 x B x N\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(embedded)\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output).squeeze(0))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data.\n",
    "batch_size = 3\n",
    "kopi_data = KopitiamDataset(singlish_sents, english_sents)\n",
    "dataloader = DataLoader(dataset=kopi_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the network for encoder and decoder.\n",
    "hidden_size = 7\n",
    "_encoder = EncoderRNN(len(kopi_data.src_vocab), hidden_size)\n",
    "_decoder = DecoderRNN(hidden_size, len(kopi_data.trg_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_batch = sort_batch_by_len(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 68, 67,  9,  8,  6,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0],\n",
       "         [ 2, 49, 46,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0],\n",
       "         [ 2, 68, 50,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0]]), tensor([7, 4, 4]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_batch['x'], _data_batch['x_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 19])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The input is of shape:\n",
    "# batch_size * max_len\n",
    "_data_batch['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.4711,  0.1670, -0.0423, -0.2430, -0.1199, -0.3438, -0.2065],\n",
       "        [ 0.2884, -0.1307, -0.3262,  0.1388,  0.0194, -0.5905, -0.3723],\n",
       "        [ 0.4711,  0.1670, -0.0423, -0.2430, -0.1199, -0.3438, -0.2065],\n",
       "        [ 0.6877,  0.2292,  0.0277, -0.3754, -0.5996,  0.0718, -0.4156],\n",
       "        [ 0.2977, -0.3155, -0.2943, -0.1023,  0.1322, -0.1422, -0.4764],\n",
       "        [ 0.5842,  0.1597, -0.1575, -0.3117, -0.3304, -0.2241, -0.4912],\n",
       "        [ 0.4285,  0.0400, -0.0914, -0.3507, -0.2297, -0.2071, -0.4237],\n",
       "        [ 0.4695, -0.2642, -0.2785, -0.2136,  0.0589, -0.2547, -0.4357],\n",
       "        [ 0.5648,  0.0905, -0.2146, -0.3627, -0.2205, -0.3412, -0.4964],\n",
       "        [ 0.3469,  0.1132,  0.1102, -0.0685, -0.0318, -0.4626, -0.3211],\n",
       "        [ 0.4540,  0.0738,  0.2436, -0.2694,  0.1291, -0.4037, -0.0727],\n",
       "        [ 0.5045,  0.0296, -0.0128, -0.3299,  0.0357, -0.3797, -0.2780]],\n",
       "       grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 3, 3, 1, 1, 1])),\n",
       " tensor([[[ 0.5045,  0.0296, -0.0128, -0.3299,  0.0357, -0.3797, -0.2780],\n",
       "          [ 0.4695, -0.2642, -0.2785, -0.2136,  0.0589, -0.2547, -0.4357],\n",
       "          [ 0.5648,  0.0905, -0.2146, -0.3627, -0.2205, -0.3412, -0.4964]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_encoder(_data_batch['x'], _data_batch['x_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.2711,  0.0875, -0.0224,  0.0294, -0.2760, -0.2569, -0.3175],\n",
       "        [ 0.4711,  0.1670, -0.0423, -0.2430, -0.1199, -0.3438, -0.2065],\n",
       "        [ 0.2884, -0.1307, -0.3262,  0.1388,  0.0194, -0.5905, -0.3723],\n",
       "        [ 0.4711,  0.1670, -0.0423, -0.2430, -0.1199, -0.3438, -0.2065],\n",
       "        [ 0.6877,  0.2292,  0.0277, -0.3754, -0.5996,  0.0718, -0.4156],\n",
       "        [ 0.2977, -0.3155, -0.2943, -0.1023,  0.1322, -0.1422, -0.4764],\n",
       "        [ 0.5842,  0.1597, -0.1575, -0.3117, -0.3304, -0.2241, -0.4912],\n",
       "        [ 0.4285,  0.0400, -0.0914, -0.3507, -0.2297, -0.2071, -0.4237],\n",
       "        [ 0.4695, -0.2642, -0.2785, -0.2136,  0.0589, -0.2547, -0.4357],\n",
       "        [ 0.5648,  0.0905, -0.2146, -0.3627, -0.2205, -0.3412, -0.4964],\n",
       "        [ 0.3469,  0.1132,  0.1102, -0.0685, -0.0318, -0.4626, -0.3211],\n",
       "        [ 0.4540,  0.0738,  0.2436, -0.2694,  0.1291, -0.4037, -0.0727],\n",
       "        [ 0.5045,  0.0296, -0.0128, -0.3299,  0.0357, -0.3797, -0.2780]],\n",
       "       grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 3, 3, 1, 1, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_encoder(_data_batch['x'], _data_batch['x_len'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dictionary([['VIknesh is a'],['dads dada']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
    "t.patch_with_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6 unique tokens: ['VIknesh is a', 'dads dada', '<pad>', '<unk>', '<s>']...)\n"
     ]
    }
   ],
   "source": [
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(t.doc2idx(['VIknesh is a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
